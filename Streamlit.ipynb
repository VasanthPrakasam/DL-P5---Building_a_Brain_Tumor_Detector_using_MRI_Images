{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKimkyhXcfy93BvuNO961O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VasanthPrakasam/DL-P5---Building_a_Brain_Tumor_Detector_using_MRI_Images/blob/main/Streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Vasanth_P')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7c3r-ZqZXwU",
        "outputId": "6c5f3d31-84a4-4644-cccb-d176eaa43fc4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Vasanth_P\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgT4loPLZzhL",
        "outputId": "beafbea0-bfd2-471a-e888-b9ef65845f32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m135.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.49.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install required packages\n",
        "!pip install streamlit plotly pyngrok -q"
      ],
      "metadata": {
        "id": "KZ_Sm4FSbWln"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import io\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ],
      "metadata": {
        "id": "T4HVJhDuZwoN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Create the Streamlit app file\n",
        "app_code = '''\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import io\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import os\n",
        "\n",
        "# Configure page\n",
        "st.set_page_config(\n",
        "    page_title=\"Brain Tumor MRI Classification\",\n",
        "    page_icon=\"🧠\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS for better styling\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".main-header {\n",
        "    font-size: 3rem;\n",
        "    color: #1f77b4;\n",
        "    text-align: center;\n",
        "    margin-bottom: 2rem;\n",
        "}\n",
        ".sub-header {\n",
        "    font-size: 1.5rem;\n",
        "    color: #2c3e50;\n",
        "    margin: 1rem 0;\n",
        "}\n",
        ".metric-container {\n",
        "    background-color: #f8f9fa;\n",
        "    padding: 1rem;\n",
        "    border-radius: 0.5rem;\n",
        "    margin: 0.5rem 0;\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Title\n",
        "st.markdown('<h1 class=\"main-header\">🧠 Brain Tumor MRI Classification System</h1>', unsafe_allow_html=True)\n",
        "\n",
        "# Sidebar for navigation\n",
        "st.sidebar.title(\"Navigation\")\n",
        "page = st.sidebar.selectbox(\"Choose a page:\",\n",
        "                           [\"Home\", \"Model Prediction\", \"Model Comparison\", \"Dataset Overview\"])\n",
        "\n",
        "# Load models function\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    \"\"\"Load pre-trained models\"\"\"\n",
        "    models = {}\n",
        "\n",
        "    # Updated model path - adjust this to your actual path\n",
        "    model_path = 'your model path'\n",
        "\n",
        "    try:\n",
        "        if os.path.exists(model_path):\n",
        "            models['MobileNet'] = keras.models.load_model(model_path)\n",
        "            st.sidebar.success(\"✅ MobileNet model loaded successfully!\")\n",
        "        else:\n",
        "            st.sidebar.error(f\"❌ Model file not found at: {model_path}\")\n",
        "            st.sidebar.info(\"Please check if the model file exists at the specified path.\")\n",
        "    except Exception as e:\n",
        "        st.sidebar.error(f\"❌ Error loading model: {str(e)}\")\n",
        "\n",
        "    return models\n",
        "\n",
        "# Image preprocessing function\n",
        "def preprocess_image(image, target_size=(224, 224)):\n",
        "    \"\"\"Preprocess image for model prediction\"\"\"\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "    # Resize image\n",
        "    image = image.resize(target_size)\n",
        "\n",
        "    # Convert to array and normalize\n",
        "    img_array = np.array(image)\n",
        "    img_array = img_array.astype('float32') / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "# Class names\n",
        "CLASS_NAMES = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "# Home Page\n",
        "if page == \"Home\":\n",
        "    st.markdown('<h2 class=\"sub-header\">Welcome to Brain Tumor MRI Classification System</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.markdown(\"\"\"\n",
        "        ### About This Project\n",
        "\n",
        "        This application uses deep learning models to classify brain tumor types from MRI images.\n",
        "        The system can identify four different categories:\n",
        "\n",
        "        - **Glioma**: A type of brain tumor that occurs in the brain and spinal cord\n",
        "        - **Meningioma**: A tumor that arises from the meninges\n",
        "        - **Pituitary**: Tumors that form in the pituitary gland\n",
        "        - **No Tumor**: Normal brain scans without tumors\n",
        "\n",
        "        ### Features\n",
        "        - 🔍 **Real-time Prediction**: Upload MRI images for instant classification\n",
        "        - 📊 **Model Comparison**: Compare performance of different CNN architectures\n",
        "        - 📈 **Visualization**: Interactive charts and confusion matrices\n",
        "        - 🧠 **Multiple Models**: VGG16, ResNet50, MobileNet, InceptionV3, EfficientNetB0\n",
        "        \"\"\")\n",
        "\n",
        "    with col2:\n",
        "        # Using a placeholder image\n",
        "        st.markdown(\"### 🧠 MRI Scan\")\n",
        "        st.info(\"Upload an MRI image in the Model Prediction section to see classification results.\")\n",
        "\n",
        "    # Quick stats\n",
        "    st.markdown('<h3 class=\"sub-header\">Project Statistics</h3>', unsafe_allow_html=True)\n",
        "\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "    with col1:\n",
        "        st.metric(\"Models Trained\", \"5\", \"CNN Architectures\")\n",
        "\n",
        "    with col2:\n",
        "        st.metric(\"Best Accuracy\", \"95.2%\", \"MobileNet\")\n",
        "\n",
        "    with col3:\n",
        "        st.metric(\"Image Classes\", \"4\", \"Tumor Types\")\n",
        "\n",
        "    with col4:\n",
        "        st.metric(\"Input Size\", \"224x224\", \"Pixels\")\n",
        "\n",
        "# Model Prediction Page\n",
        "elif page == \"Model Prediction\":\n",
        "    st.markdown('<h2 class=\"sub-header\">🔍 MRI Image Classification</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    # Load models\n",
        "    models = load_models()\n",
        "\n",
        "    if not models:\n",
        "        st.error(\"⚠️ No models available. Please ensure the model file is properly saved and the path is correct.\")\n",
        "        st.info(\"\"\"\n",
        "        **To fix this:**\n",
        "        1. Make sure you've trained and saved the MobileNet model\n",
        "        2. Check the file path in the code\n",
        "        3. Verify the model file exists at the specified location\n",
        "        \"\"\")\n",
        "        st.stop()\n",
        "\n",
        "    # Model selection\n",
        "    selected_model = st.selectbox(\"Select Model:\", list(models.keys()))\n",
        "\n",
        "    # File uploader\n",
        "    uploaded_file = st.file_uploader(\n",
        "        \"Upload an MRI image\",\n",
        "        type=['jpg', 'jpeg', 'png', 'bmp'],\n",
        "        help=\"Upload a brain MRI scan image for classification\"\n",
        "    )\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Display uploaded image\n",
        "        col1, col2 = st.columns([1, 1])\n",
        "\n",
        "        with col1:\n",
        "            image = Image.open(uploaded_file)\n",
        "            st.image(image, caption=\"Uploaded MRI Image\", use_container_width=True)\n",
        "\n",
        "            # Image info\n",
        "            st.info(f\"\"\"\n",
        "            **Image Details:**\n",
        "            - Size: {image.size}\n",
        "            - Mode: {image.mode}\n",
        "            - Format: {uploaded_file.type}\n",
        "            \"\"\")\n",
        "\n",
        "        with col2:\n",
        "            # Preprocess and predict\n",
        "            with st.spinner(\"🔄 Processing image and making prediction...\"):\n",
        "                try:\n",
        "                    processed_image = preprocess_image(image)\n",
        "\n",
        "                    # Make prediction\n",
        "                    prediction = models[selected_model].predict(processed_image, verbose=0)\n",
        "                    predicted_class_idx = np.argmax(prediction[0])\n",
        "                    predicted_class = CLASS_NAMES[predicted_class_idx]\n",
        "                    confidence = prediction[0][predicted_class_idx] * 100\n",
        "\n",
        "                    # Display results\n",
        "                    st.success(f\"**🎯 Prediction: {predicted_class.upper()}**\")\n",
        "                    st.info(f\"**📊 Confidence: {confidence:.2f}%**\")\n",
        "\n",
        "                    # Progress bar for confidence\n",
        "                    st.progress(float(confidence / 100))\n",
        "\n",
        "                    # Prediction probabilities\n",
        "                    st.markdown(\"### 📈 Prediction Probabilities\")\n",
        "                    prob_df = pd.DataFrame({\n",
        "                        'Class': CLASS_NAMES,\n",
        "                        'Probability': prediction[0] * 100\n",
        "                    })\n",
        "\n",
        "                    # Bar chart\n",
        "                    fig = px.bar(prob_df, x='Class', y='Probability',\n",
        "                               title='Prediction Probabilities by Class',\n",
        "                               color='Probability',\n",
        "                               color_continuous_scale='viridis')\n",
        "                    fig.update_layout(height=400)\n",
        "                    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "                    # Detailed probabilities table\n",
        "                    st.markdown(\"### 📋 Detailed Results\")\n",
        "                    for i, (class_name, prob) in enumerate(zip(CLASS_NAMES, prediction[0])):\n",
        "                        if i == predicted_class_idx:\n",
        "                            st.markdown(f\"**✅ {class_name.title()}: {prob*100:.2f}%** ← Predicted\")\n",
        "                        else:\n",
        "                            st.markdown(f\"⚪ {class_name.title()}: {prob*100:.2f}%\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"❌ Error during prediction: {str(e)}\")\n",
        "    else:\n",
        "        st.info(\"👆 Please upload an MRI image to start classification\")\n",
        "\n",
        "# Model Comparison Page\n",
        "elif page == \"Model Comparison\":\n",
        "    st.markdown('<h2 class=\"sub-header\">📊 Model Performance Comparison</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    # Model comparison data (you can update this with your actual results)\n",
        "    model_data = {\n",
        "        'Model': ['VGG16', 'ResNet50', 'MobileNet', 'InceptionV3', 'EfficientNetB0'],\n",
        "        'Val_Accuracy': [0.924, 0.931, 0.952, 0.918, 0.943],\n",
        "        'Val_Precision': [0.925, 0.933, 0.954, 0.919, 0.944],\n",
        "        'Val_Recall': [0.923, 0.930, 0.951, 0.917, 0.942],\n",
        "        'Parameters': ['138,357,544', '25,636,712', '4,253,864', '23,851,784', '5,330,571'],\n",
        "        'Inference_Time': ['Medium', 'Medium', 'Fast', 'Medium', 'Fast']\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(model_data)\n",
        "\n",
        "    # Display dataframe\n",
        "    st.markdown(\"### 📋 Model Performance Table\")\n",
        "    st.dataframe(df, use_container_width=True)\n",
        "\n",
        "    # Performance comparison charts\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        # Accuracy comparison\n",
        "        fig_acc = px.bar(df, x='Model', y='Val_Accuracy',\n",
        "                        title='Validation Accuracy Comparison',\n",
        "                        color='Val_Accuracy',\n",
        "                        color_continuous_scale='blues')\n",
        "        fig_acc.update_layout(height=400)\n",
        "        st.plotly_chart(fig_acc, use_container_width=True)\n",
        "\n",
        "    with col2:\n",
        "        # Multi-metric comparison\n",
        "        metrics_df = df[['Model', 'Val_Accuracy', 'Val_Precision', 'Val_Recall']].melt(\n",
        "            id_vars='Model', var_name='Metric', value_name='Score'\n",
        "        )\n",
        "\n",
        "        fig_metrics = px.line(metrics_df, x='Model', y='Score', color='Metric',\n",
        "                             title='Multi-Metric Performance Comparison',\n",
        "                             markers=True)\n",
        "        fig_metrics.update_layout(height=400)\n",
        "        st.plotly_chart(fig_metrics, use_container_width=True)\n",
        "\n",
        "    # Best model highlight\n",
        "    best_model_idx = df['Val_Accuracy'].idxmax()\n",
        "    best_model = df.iloc[best_model_idx]\n",
        "\n",
        "    st.markdown(\"### 🏆 Best Performing Model\")\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "    with col1:\n",
        "        st.metric(\"Model\", best_model['Model'])\n",
        "    with col2:\n",
        "        st.metric(\"Accuracy\", f\"{best_model['Val_Accuracy']:.3f}\")\n",
        "    with col3:\n",
        "        st.metric(\"Precision\", f\"{best_model['Val_Precision']:.3f}\")\n",
        "    with col4:\n",
        "        st.metric(\"Recall\", f\"{best_model['Val_Recall']:.3f}\")\n",
        "\n",
        "# Dataset Overview Page\n",
        "elif page == \"Dataset Overview\":\n",
        "    st.markdown('<h2 class=\"sub-header\">📈 Dataset Overview</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    # Dataset statistics\n",
        "    dataset_stats = {\n",
        "        'Class': ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary'],\n",
        "        'Train_Images': [826, 822, 395, 827],\n",
        "        'Validation_Images': [100, 115, 105, 74],\n",
        "        'Test_Images': [100, 115, 105, 74]\n",
        "    }\n",
        "\n",
        "    stats_df = pd.DataFrame(dataset_stats)\n",
        "\n",
        "    # Display statistics table\n",
        "    st.markdown(\"### 📊 Dataset Distribution\")\n",
        "    st.dataframe(stats_df, use_container_width=True)\n",
        "\n",
        "    # Visualizations\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        # Training data distribution\n",
        "        fig_train = px.pie(stats_df, values='Train_Images', names='Class',\n",
        "                          title='Training Data Distribution')\n",
        "        fig_train.update_layout(height=400)\n",
        "        st.plotly_chart(fig_train, use_container_width=True)\n",
        "\n",
        "    with col2:\n",
        "        # Total distribution across splits\n",
        "        melted_df = stats_df.melt(id_vars='Class',\n",
        "                                 value_vars=['Train_Images', 'Validation_Images', 'Test_Images'],\n",
        "                                 var_name='Split', value_name='Count')\n",
        "\n",
        "        fig_split = px.bar(melted_df, x='Class', y='Count', color='Split',\n",
        "                          title='Data Distribution Across Splits',\n",
        "                          barmode='group')\n",
        "        fig_split.update_layout(height=400)\n",
        "        st.plotly_chart(fig_split, use_container_width=True)\n",
        "\n",
        "    # Dataset summary\n",
        "    total_images = stats_df[['Train_Images', 'Validation_Images', 'Test_Images']].sum().sum()\n",
        "\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "    with col1:\n",
        "        st.metric(\"Total Images\", f\"{total_images:,}\")\n",
        "\n",
        "    with col2:\n",
        "        st.metric(\"Classes\", len(CLASS_NAMES))\n",
        "\n",
        "    with col3:\n",
        "        st.metric(\"Training Images\", f\"{stats_df['Train_Images'].sum():,}\")\n",
        "\n",
        "    with col4:\n",
        "        st.metric(\"Test Images\", f\"{stats_df['Test_Images'].sum():,}\")\n",
        "\n",
        "    # Data augmentation info\n",
        "    st.markdown(\"### 🔄 Data Augmentation Applied\")\n",
        "    st.info(\"\"\"\n",
        "    **Training Data Augmentation:**\n",
        "    - Rotation: ±20 degrees\n",
        "    - Width/Height Shift: ±20%\n",
        "    - Horizontal Flip: Enabled\n",
        "    - Zoom Range: 80%-120%\n",
        "    - Rescaling: 1/255\n",
        "    \"\"\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"**🧠 Brain Tumor MRI Classification System** | Built with Streamlit and TensorFlow\")\n",
        "'''\n",
        "\n",
        "# Write the app to a file\n",
        "with open('/content/brain_tumor_app.py', 'w') as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\"✅ Streamlit app file created successfully!\")\n",
        "print(\"📄 File saved as: /content/brain_tumor_app.py\")\n",
        "\n",
        "# STEP 3: Set up ngrok authentication (you need to get this token from ngrok.com)\n",
        "print(\"\\n🔐 Setting up ngrok...\")\n",
        "print(\"⚠️  You need to get your authtoken from https://ngrok.com (free account)\")\n",
        "print(\"📝 After getting the token, run: ngrok.set_auth_token('your_token_here')\")\n",
        "\n",
        "# STEP 4: Instructions for running\n",
        "print(\"\\n🚀 To run the app, execute the following commands:\")\n",
        "print(\"1. First set your ngrok token:\")\n",
        "print(\"   from pyngrok import ngrok\")\n",
        "print(\"   ngrok.set_auth_token('YOUR_TOKEN_HERE')\")\n",
        "print(\"\\n2. Then run the app:\")\n",
        "print(\"   !streamlit run /content/brain_tumor_app.py --server.port 8501 --server.address 0.0.0.0 &\")\n",
        "print(\"   from pyngrok import ngrok\")\n",
        "print(\"   public_url = ngrok.connect(8501)\")\n",
        "print(\"   print(f'🌐 App URL: {public_url}')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VZWS004mY0bd",
        "outputId": "a1a8c8c4-f5d1-43c6-8b70-823bf11ccd3c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Streamlit app file created successfully!\n",
            "📄 File saved as: /content/brain_tumor_app.py\n",
            "\n",
            "🔐 Setting up ngrok...\n",
            "⚠️  You need to get your authtoken from https://ngrok.com (free account)\n",
            "📝 After getting the token, run: ngrok.set_auth_token('your_token_here')\n",
            "\n",
            "🚀 To run the app, execute the following commands:\n",
            "1. First set your ngrok token:\n",
            "   from pyngrok import ngrok\n",
            "   ngrok.set_auth_token('YOUR_TOKEN_HERE')\n",
            "\n",
            "2. Then run the app:\n",
            "   !streamlit run /content/brain_tumor_app.py --server.port 8501 --server.address 0.0.0.0 &\n",
            "   from pyngrok import ngrok\n",
            "   public_url = ngrok.connect(8501)\n",
            "   print(f'🌐 App URL: {public_url}')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# CELL 1: Run the setup code above first\n",
        "# ================================================================\n",
        "\n",
        "# ================================================================\n",
        "# CELL 2: Set up ngrok (you need to register at ngrok.com for free)\n",
        "# ================================================================\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Get your auth token from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "# Replace 'YOUR_TOKEN_HERE' with your actual token\n",
        "try:\n",
        "    ngrok.set_auth_token('your token')  # Replace with your actual token\n",
        "    print(\"✅ Ngrok authentication successful!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Ngrok auth failed: {e}\")\n",
        "    print(\"🔗 Get your token from: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "\n",
        "# ================================================================\n",
        "# CELL 3: Start Streamlit app\n",
        "# ================================================================\n",
        "import subprocess\n",
        "import time\n",
        "from threading import Thread\n",
        "\n",
        "def run_streamlit():\n",
        "    \"\"\"Function to run streamlit in background\"\"\"\n",
        "    cmd = [\n",
        "        \"streamlit\", \"run\", \"/content/brain_tumor_app.py\",\n",
        "        \"--server.port\", \"8501\",\n",
        "        \"--server.address\", \"0.0.0.0\",\n",
        "        \"--server.headless\", \"true\"\n",
        "    ]\n",
        "    subprocess.run(cmd)\n",
        "\n",
        "# Start Streamlit in background thread\n",
        "thread = Thread(target=run_streamlit)\n",
        "thread.daemon = True\n",
        "thread.start()\n",
        "\n",
        "print(\"🚀 Starting Streamlit app...\")\n",
        "time.sleep(5)  # Wait for app to start\n",
        "\n",
        "# ================================================================\n",
        "# CELL 4: Create public URL with ngrok\n",
        "# ================================================================\n",
        "try:\n",
        "    # Create ngrok tunnel\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"\\n🌐 Your Brain Tumor Classification App is live at:\")\n",
        "    print(f\"🔗 {public_url}\")\n",
        "    print(f\"\\n📱 Click the link above to access your app!\")\n",
        "\n",
        "    # Keep connection info\n",
        "    tunnels = ngrok.get_tunnels()\n",
        "    print(f\"\\n📊 Active tunnels: {len(tunnels)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error creating ngrok tunnel: {e}\")\n",
        "    print(\"💡 Make sure you've set the correct auth token in Cell 2\")\n",
        "\n",
        "# ================================================================\n",
        "# CELL 5: (Optional) Check app status and stop if needed\n",
        "# ================================================================\n",
        "# To check tunnel status\n",
        "print(\"🔍 Checking tunnel status...\")\n",
        "tunnels = ngrok.get_tunnels()\n",
        "for tunnel in tunnels:\n",
        "    print(f\"✅ Tunnel: {tunnel.public_url} -> {tunnel.config['addr']}\")\n",
        "\n",
        "# To stop all tunnels (run this when done)\n",
        "# ngrok.kill()\n",
        "# print(\"🛑 All tunnels stopped\")\n",
        "\n",
        "# ================================================================\n",
        "# ALTERNATIVE: If ngrok doesn't work, use Colab's built-in method\n",
        "# ================================================================\n",
        "# Uncomment this section if ngrok gives issues\n",
        "\n",
        "\"\"\"\n",
        "# Alternative method using subprocess and localhost\n",
        "import subprocess\n",
        "from IPython.display import Javascript\n",
        "import time\n",
        "\n",
        "# Start streamlit\n",
        "proc = subprocess.Popen([\n",
        "    \"streamlit\", \"run\", \"/content/brain_tumor_app.py\",\n",
        "    \"--server.port\", \"8501\"\n",
        "])\n",
        "\n",
        "time.sleep(5)\n",
        "print(\"🚀 Streamlit started on port 8501\")\n",
        "print(\"⚠️  In Colab, you might need to use port forwarding or ngrok\")\n",
        "print(\"🔗 Try accessing: https://localhost:8501 (may not work in Colab)\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "ooF2jep1a192",
        "outputId": "f8696454-f475-43a0-a4df-233fe4fa8067"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Ngrok authentication successful!\n",
            "🚀 Starting Streamlit app...\n",
            "\n",
            "🌐 Your Brain Tumor Classification App is live at:\n",
            "🔗 NgrokTunnel: \"https://1c5702590d2f.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "📱 Click the link above to access your app!\n",
            "\n",
            "📊 Active tunnels: 1\n",
            "🔍 Checking tunnel status...\n",
            "✅ Tunnel: https://1c5702590d2f.ngrok-free.app -> http://localhost:8501\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Alternative method using subprocess and localhost\\nimport subprocess\\nfrom IPython.display import Javascript\\nimport time\\n\\n# Start streamlit\\nproc = subprocess.Popen([\\n    \"streamlit\", \"run\", \"/content/brain_tumor_app.py\", \\n    \"--server.port\", \"8501\"\\n])\\n\\ntime.sleep(5)\\nprint(\"🚀 Streamlit started on port 8501\")\\nprint(\"⚠️  In Colab, you might need to use port forwarding or ngrok\")\\nprint(\"🔗 Try accessing: https://localhost:8501 (may not work in Colab)\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}